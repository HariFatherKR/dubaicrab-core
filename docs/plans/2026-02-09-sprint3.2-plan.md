# Sprint 3.2: RAG ê¸°ì´ˆ ê°œë°œ ê³„íš

**ì‘ì„±ì¼**: 2026-02-09  
**Sprint ê¸°ê°„**: 3ì£¼ (2026-02-10 ~ 2026-02-28)  
**ëª©í‘œ**: ê³µë¬´ì› ë¬¸ì„œ(HWP) ê¸°ë°˜ RAG ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ MVP êµ¬í˜„

---

## 1. ëª©í‘œ ë° ë²”ìœ„

### 1.1 Sprint ëª©í‘œ

1. **HWP ë¬¸ì„œ ë²¡í„°í™”**: ê³µë¬´ì› ë¬¸ì„œ(HWP)ë¥¼ í…ìŠ¤íŠ¸ë¡œ ì¶”ì¶œí•˜ê³  ë²¡í„° ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
2. **ë²¡í„° ê²€ìƒ‰**: ìì—°ì–´ ì§ˆì˜ë¡œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
3. **RAG í†µí•©**: ê²€ìƒ‰ ê²°ê³¼ë¥¼ LLM ì»¨í…ìŠ¤íŠ¸ë¡œ í™œìš©í•˜ì—¬ ì •í™•í•œ ë‹µë³€ ìƒì„±

### 1.2 ë²”ìœ„

**In Scope:**

- Chroma ë²¡í„° DB ì„¤ì •
- BGE-M3 ì„ë² ë”© í†µí•©
- HWP â†’ í…ìŠ¤íŠ¸ â†’ ì²­í¬ â†’ ì„ë² ë”© íŒŒì´í”„ë¼ì¸
- ê²€ìƒ‰ API ì—”ë“œí¬ì¸íŠ¸
- ê¸°ë³¸ ì±„íŒ… RAG í†µí•©

**Out of Scope (í–¥í›„ Sprint):**

- ë³µì¡í•œ ë¦¬ë­í‚¹ ì „ëµ
- ë‹¤ì¤‘ ì¸ë±ìŠ¤ ê´€ë¦¬ UI
- ì‹¤ì‹œê°„ ë¬¸ì„œ ë™ê¸°í™”
- í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (BM25 + Dense)

---

## 2. RICE ìš°ì„ ìˆœìœ„ ë¶„ì„

### 2.1 ì ìˆ˜ ê¸°ì¤€

| ì§€í‘œ           | ì„¤ëª…                        | ì ìˆ˜ ë²”ìœ„               |
| -------------- | --------------------------- | ----------------------- |
| **Reach**      | ì˜í–¥ë°›ëŠ” ì‚¬ìš©ì/ê¸°ëŠ¥ ìˆ˜     | 1-10                    |
| **Impact**     | ë¹„ì¦ˆë‹ˆìŠ¤/UX ì˜í–¥ë„          | 0.25 (ìµœì†Œ) ~ 3 (ìµœëŒ€)  |
| **Confidence** | ì„±ê³µ í™•ì‹ ë„                 | 0.5 (ë‚®ìŒ) ~ 1.0 (ë†’ìŒ) |
| **Effort**     | í•„ìš” ì¸ë ¥-ì£¼ (person-weeks) | 0.5 ~ 4                 |

**RICE ì ìˆ˜ = (Reach Ã— Impact Ã— Confidence) / Effort**

### 2.2 íƒœìŠ¤í¬ë³„ RICE ë¶„ì„

#### P0 (í•µì‹¬ ì¸í”„ë¼) - RICE â‰¥ 10

| íƒœìŠ¤í¬                | R   | I   | C   | E   | RICE     | ìš°ì„ ìˆœìœ„ |
| --------------------- | --- | --- | --- | --- | -------- | -------- |
| P0-1: í™˜ê²½ ì„¤ì •       | 10  | 3.0 | 1.0 | 0.4 | **75.0** | ğŸ”´ P0    |
| P0-2: HWP í…ìŠ¤íŠ¸ ì¶”ì¶œ | 10  | 3.0 | 0.8 | 0.6 | **40.0** | ğŸ”´ P0    |
| P0-3: ì²­í‚¹ íŒŒì´í”„ë¼ì¸ | 10  | 2.0 | 0.9 | 0.4 | **45.0** | ğŸ”´ P0    |
| P0-4: ë²¡í„° ì¸ë±ì‹±     | 10  | 2.0 | 0.9 | 0.4 | **45.0** | ğŸ”´ P0    |

**ë¶„ì„:**

- í™˜ê²½ ì„¤ì •ì´ ê°€ì¥ ë†’ì€ RICE (ì˜ì¡´ì„± ìµœìƒìœ„)
- HWP ì¶”ì¶œì€ ë¶ˆí™•ì‹¤ì„±ì´ ìˆì–´ Confidence ë‚®ìŒ (LibreOffice ì˜ì¡´)
- ëª¨ë“  P0 íƒœìŠ¤í¬ëŠ” ì˜ì¡´ì„± ìˆœì„œëŒ€ë¡œ ì§„í–‰ í•„ìˆ˜

#### P1 (ê²€ìƒ‰ API) - RICE 5-10

| íƒœìŠ¤í¬                   | R   | I   | C   | E   | RICE     | ìš°ì„ ìˆœìœ„ |
| ------------------------ | --- | --- | --- | --- | -------- | -------- |
| P1-1: ê²€ìƒ‰ ì—”ì§„          | 8   | 2.0 | 0.9 | 0.4 | **36.0** | ğŸŸ¡ P1    |
| P1-2: FastAPI ì—”ë“œí¬ì¸íŠ¸ | 8   | 2.0 | 0.9 | 0.4 | **36.0** | ğŸŸ¡ P1    |
| P1-3: ì±„íŒ… í†µí•©          | 10  | 2.0 | 0.8 | 0.2 | **80.0** | ğŸŸ¡ P1    |

**ë¶„ì„:**

- ì±„íŒ… í†µí•©ì´ ê°€ì¥ ë†’ì€ ì‚¬ìš©ì ì„íŒ©íŠ¸
- ê²€ìƒ‰ ì—”ì§„ê³¼ APIëŠ” ë™ì¼ ìš°ì„ ìˆœìœ„

#### P2 (ê³ ê¸‰ ê¸°ëŠ¥) - RICE < 5

| íƒœìŠ¤í¬               | R   | I   | C   | E   | RICE     | ìš°ì„ ìˆœìœ„ |
| -------------------- | --- | --- | --- | --- | -------- | -------- |
| P2-1: ë¦¬ë­í‚¹         | 5   | 1.0 | 0.7 | 0.4 | **8.75** | ğŸŸ¢ P2    |
| P2-2: ë‹¤ì¤‘ íŒŒì¼ í˜•ì‹ | 6   | 1.0 | 0.8 | 0.4 | **12.0** | ğŸŸ¢ P2    |
| P2-3: ì¸ë±ìŠ¤ ê´€ë¦¬ UI | 3   | 0.5 | 0.6 | 0.6 | **1.5**  | ğŸŸ¢ P2    |

**ë¶„ì„:**

- ë¦¬ë­í‚¹ì€ í’ˆì§ˆ ê°œì„ ìš©, MVPì—ì„œ ì„ íƒì 
- ê´€ë¦¬ UIëŠ” ìš°ì„ ìˆœìœ„ ìµœí•˜ìœ„

---

## 3. ê¸°ìˆ  ìŠ¤í™ ìƒì„¸

### 3.1 Chroma ì„¤ì¹˜ ë° ì´ˆê¸°í™”

#### ì„¤ì¹˜

```bash
pip install chromadb>=0.4.0
```

#### ì´ˆê¸°í™” ì½”ë“œ

```python
# src/rag/vector_store.py

import chromadb
from chromadb.config import Settings
from pathlib import Path

class VectorStore:
    """Chroma ë²¡í„° ìŠ¤í† ì–´ ë˜í¼"""

    def __init__(self, persist_dir: str = "data/chroma"):
        self.persist_dir = Path(persist_dir)
        self.persist_dir.mkdir(parents=True, exist_ok=True)

        self.client = chromadb.PersistentClient(
            path=str(self.persist_dir),
            settings=Settings(
                anonymized_telemetry=False,
                allow_reset=True
            )
        )

    def get_or_create_collection(
        self,
        name: str = "documents",
        embedding_function=None
    ):
        """ì»¬ë ‰ì…˜ ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°"""
        return self.client.get_or_create_collection(
            name=name,
            embedding_function=embedding_function,
            metadata={"hnsw:space": "cosine"}
        )

    def delete_collection(self, name: str):
        """ì»¬ë ‰ì…˜ ì‚­ì œ"""
        self.client.delete_collection(name)

    def list_collections(self):
        """ëª¨ë“  ì»¬ë ‰ì…˜ ëª©ë¡"""
        return [c.name for c in self.client.list_collections()]
```

#### ì„¤ì •

```python
# src/rag/config.py

from pydantic_settings import BaseSettings

class RAGSettings(BaseSettings):
    # Chroma
    chroma_persist_dir: str = "data/chroma"
    chroma_collection: str = "dubaicrab_docs"

    # Embedding
    embedding_model: str = "BAAI/bge-m3"
    embedding_device: str = "mps"  # cuda, mps, cpu
    embedding_batch_size: int = 32

    # Chunking
    chunk_size: int = 512
    chunk_overlap: int = 50
    min_chunk_length: int = 50
    max_chunk_length: int = 2000

    # Search
    default_top_k: int = 5
    min_similarity: float = 0.5

    class Config:
        env_prefix = "RAG_"
```

---

### 3.2 BGE-M3 ì„ë² ë”© ì„¤ì •

#### ì„¤ì¹˜

```bash
pip install FlagEmbedding>=1.2.0
```

#### ì„ë² ë”© ëª¨ë“ˆ

```python
# src/rag/embeddings.py

from typing import List, Union
from FlagEmbedding import BGEM3FlagModel
import numpy as np

class BGEEmbeddings:
    """BGE-M3 ì„ë² ë”© ë˜í¼"""

    _instance = None
    _model = None

    def __new__(cls, *args, **kwargs):
        """ì‹±ê¸€í†¤ íŒ¨í„´ - ëª¨ë¸ í•œ ë²ˆë§Œ ë¡œë“œ"""
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(
        self,
        model_name: str = "BAAI/bge-m3",
        use_fp16: bool = True,
        device: str = "mps"
    ):
        if self._model is None:
            self._model = BGEM3FlagModel(
                model_name,
                use_fp16=use_fp16,
                device=device
            )

    def encode(
        self,
        texts: Union[str, List[str]],
        batch_size: int = 32,
        max_length: int = 8192,
        return_dense: bool = True,
        return_sparse: bool = False
    ) -> np.ndarray:
        """í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
        if isinstance(texts, str):
            texts = [texts]

        embeddings = self._model.encode(
            texts,
            batch_size=batch_size,
            max_length=max_length,
            return_dense=return_dense,
            return_sparse=return_sparse
        )

        if return_dense and not return_sparse:
            return embeddings['dense_vecs']
        return embeddings

    @property
    def dimension(self) -> int:
        """ì„ë² ë”© ì°¨ì›"""
        return 1024
```

#### Chromaìš© ì„ë² ë”© í•¨ìˆ˜

```python
# src/rag/chroma_embeddings.py

from chromadb import EmbeddingFunction
from .embeddings import BGEEmbeddings

class BGEChromaEmbeddingFunction(EmbeddingFunction):
    """Chromaìš© BGE ì„ë² ë”© ì–´ëŒ‘í„°"""

    def __init__(self):
        self.embeddings = BGEEmbeddings()

    def __call__(self, input: list[str]) -> list[list[float]]:
        embeddings = self.embeddings.encode(input)
        return embeddings.tolist()
```

---

### 3.3 LlamaIndex íŒŒì´í”„ë¼ì¸ êµ¬ì¡°

#### ì„¤ì¹˜

```bash
pip install llama-index>=0.10.0
pip install llama-index-vector-stores-chroma
pip install llama-index-embeddings-huggingface
```

#### íŒŒì´í”„ë¼ì¸ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Document Loader                       â”‚
â”‚  â”œâ”€â”€ HWP Parser (LibreOffice)                           â”‚
â”‚  â”œâ”€â”€ PDF Parser (PyMuPDF)                               â”‚
â”‚  â””â”€â”€ DOCX Parser (python-docx)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Node Parser                           â”‚
â”‚  â””â”€â”€ SentenceSplitter(chunk_size=512, overlap=50)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Embedding Model                       â”‚
â”‚  â””â”€â”€ BGE-M3 (BAAI/bge-m3, dim=1024)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Vector Store                          â”‚
â”‚  â””â”€â”€ Chroma (persistent, collection=dubaicrab_docs)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Query Engine                          â”‚
â”‚  â”œâ”€â”€ VectorStoreQuery (similarity search)               â”‚
â”‚  â””â”€â”€ Response Synthesizer (LLM)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### LlamaIndex í†µí•© ì½”ë“œ

```python
# src/rag/pipeline.py

from llama_index.core import VectorStoreIndex, Settings
from llama_index.core.node_parser import SentenceSplitter
from llama_index.vector_stores.chroma import ChromaVectorStore
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
import chromadb

class RAGPipeline:
    """LlamaIndex ê¸°ë°˜ RAG íŒŒì´í”„ë¼ì¸"""

    def __init__(self, config: RAGSettings):
        self.config = config
        self._setup_settings()
        self._setup_vector_store()

    def _setup_settings(self):
        """LlamaIndex ì „ì—­ ì„¤ì •"""
        # ì„ë² ë”© ëª¨ë¸
        Settings.embed_model = HuggingFaceEmbedding(
            model_name=self.config.embedding_model,
            device=self.config.embedding_device
        )

        # ì²­í‚¹ ì„¤ì •
        Settings.node_parser = SentenceSplitter(
            chunk_size=self.config.chunk_size,
            chunk_overlap=self.config.chunk_overlap
        )

    def _setup_vector_store(self):
        """Chroma ë²¡í„° ìŠ¤í† ì–´ ì„¤ì •"""
        chroma_client = chromadb.PersistentClient(
            path=self.config.chroma_persist_dir
        )
        chroma_collection = chroma_client.get_or_create_collection(
            name=self.config.chroma_collection
        )
        self.vector_store = ChromaVectorStore(
            chroma_collection=chroma_collection
        )

    def index_documents(self, documents: list) -> VectorStoreIndex:
        """ë¬¸ì„œ ì¸ë±ì‹±"""
        return VectorStoreIndex.from_documents(
            documents,
            vector_store=self.vector_store,
            show_progress=True
        )

    def get_query_engine(self, similarity_top_k: int = 5):
        """ì¿¼ë¦¬ ì—”ì§„ ìƒì„±"""
        index = VectorStoreIndex.from_vector_store(
            vector_store=self.vector_store
        )
        return index.as_query_engine(
            similarity_top_k=similarity_top_k
        )
```

---

### 3.4 HWP â†’ í…ìŠ¤íŠ¸ â†’ ì²­í¬ â†’ ì„ë² ë”© í”Œë¡œìš°

#### í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    HWP íŒŒì¼      â”‚
â”‚  (document.hwp)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. HWP íŒŒì„œ (hwp_parser.py)         â”‚
â”‚  â”œâ”€â”€ LibreOffice headless ë³€í™˜       â”‚
â”‚  â”‚   libreoffice --convert-to txt    â”‚
â”‚  â”œâ”€â”€ hwpx ZIP ì••ì¶• í•´ì œ              â”‚
â”‚  â””â”€â”€ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ                 â”‚
â”‚      - íŒŒì¼ëª…, ì‘ì„±ì¼, ì‘ì„±ì        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (preprocessor.py)  â”‚
â”‚  â”œâ”€â”€ ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°              â”‚
â”‚  â”œâ”€â”€ íŠ¹ìˆ˜ë¬¸ì ì •ê·œí™”                 â”‚
â”‚  â””â”€â”€ í‘œ ë§ˆí¬ë‹¤ìš´ ë³€í™˜                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. ì²­í‚¹ (chunker.py)                â”‚
â”‚  â”œâ”€â”€ SentenceSplitter ì ìš©           â”‚
â”‚  â”‚   - chunk_size: 512 í† í°          â”‚
â”‚  â”‚   - overlap: 50 í† í°              â”‚
â”‚  â”œâ”€â”€ ì¡°í•­ë³„ ë¶„ë¦¬ (ì •ê·œì‹)            â”‚
â”‚  â”‚   - ì œ\d+ì¡°, ì œ\d+í•­              â”‚
â”‚  â””â”€â”€ ì²­í¬ ë©”íƒ€ë°ì´í„° ìƒì„±            â”‚
â”‚      - source, chunk_index, section  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. ì„ë² ë”© (embeddings.py)           â”‚
â”‚  â”œâ”€â”€ BGE-M3 ëª¨ë¸ ë¡œë“œ                â”‚
â”‚  â”œâ”€â”€ ë°°ì¹˜ ì¸ì½”ë”© (batch_size=32)     â”‚
â”‚  â””â”€â”€ 1024ì°¨ì› ë²¡í„° ìƒì„±              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. ë²¡í„° ì €ì¥ (vector_store.py)      â”‚
â”‚  â”œâ”€â”€ Chroma ì»¬ë ‰ì…˜ì— ì¶”ê°€            â”‚
â”‚  â”‚   - id: hash(file_path + chunk_i) â”‚
â”‚  â”‚   - embedding: float[1024]        â”‚
â”‚  â”‚   - document: chunk_text          â”‚
â”‚  â”‚   - metadata: dict                â”‚
â”‚  â””â”€â”€ ì¤‘ë³µ ì²´í¬ (upsert)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### HWP íŒŒì„œ êµ¬í˜„

```python
# src/rag/parsers/hwp_parser.py

import subprocess
import tempfile
import zipfile
import xml.etree.ElementTree as ET
from pathlib import Path
from dataclasses import dataclass
from typing import Optional
import hashlib

@dataclass
class HWPDocument:
    text: str
    metadata: dict
    file_hash: str

class HWPParser:
    """HWP/HWPX ë¬¸ì„œ íŒŒì„œ"""

    def __init__(self, timeout: int = 60):
        self.timeout = timeout

    def parse(self, file_path: str) -> HWPDocument:
        """HWP íŒŒì¼ íŒŒì‹±"""
        path = Path(file_path)

        if not path.exists():
            raise FileNotFoundError(f"íŒŒì¼ ì—†ìŒ: {file_path}")

        # íŒŒì¼ í•´ì‹œ ìƒì„±
        file_hash = self._compute_hash(path)

        # í™•ì¥ìì— ë”°ë¥¸ íŒŒì‹±
        if path.suffix.lower() == '.hwpx':
            text = self._parse_hwpx(path)
        elif path.suffix.lower() == '.hwp':
            text = self._parse_hwp_libreoffice(path)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: {path.suffix}")

        # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        metadata = {
            "source": path.name,
            "file_path": str(path.absolute()),
            "file_size": path.stat().st_size,
            "modified_at": path.stat().st_mtime,
        }

        return HWPDocument(
            text=text,
            metadata=metadata,
            file_hash=file_hash
        )

    def _parse_hwp_libreoffice(self, path: Path) -> str:
        """LibreOfficeë¡œ HWP â†’ TXT ë³€í™˜"""
        with tempfile.TemporaryDirectory() as tmpdir:
            result = subprocess.run(
                [
                    "libreoffice",
                    "--headless",
                    "--convert-to", "txt:Text",
                    "--outdir", tmpdir,
                    str(path)
                ],
                capture_output=True,
                timeout=self.timeout
            )

            if result.returncode != 0:
                raise RuntimeError(f"ë³€í™˜ ì‹¤íŒ¨: {result.stderr.decode()}")

            txt_path = Path(tmpdir) / f"{path.stem}.txt"
            if not txt_path.exists():
                raise RuntimeError("ë³€í™˜ëœ íŒŒì¼ ì—†ìŒ")

            return txt_path.read_text(encoding='utf-8')

    def _parse_hwpx(self, path: Path) -> str:
        """HWPX (OOXML) ì§ì ‘ íŒŒì‹±"""
        texts = []

        with zipfile.ZipFile(path, 'r') as zf:
            # Contents/section*.xml íŒŒì¼ë“¤ ì°¾ê¸°
            section_files = sorted([
                f for f in zf.namelist()
                if f.startswith('Contents/section') and f.endswith('.xml')
            ])

            for section_file in section_files:
                with zf.open(section_file) as f:
                    tree = ET.parse(f)
                    root = tree.getroot()
                    # ëª¨ë“  í…ìŠ¤íŠ¸ ë…¸ë“œ ì¶”ì¶œ
                    for elem in root.iter():
                        if elem.text:
                            texts.append(elem.text.strip())

        return '\n'.join(filter(None, texts))

    def _compute_hash(self, path: Path) -> str:
        """íŒŒì¼ í•´ì‹œ ê³„ì‚°"""
        hasher = hashlib.md5()
        with open(path, 'rb') as f:
            for chunk in iter(lambda: f.read(8192), b''):
                hasher.update(chunk)
        return hasher.hexdigest()
```

---

### 3.5 ê²€ìƒ‰ API ì—”ë“œí¬ì¸íŠ¸

#### API ìŠ¤í‚¤ë§ˆ

```python
# src/rag/schemas.py

from pydantic import BaseModel, Field
from typing import List, Optional
from datetime import datetime

class SearchRequest(BaseModel):
    """ê²€ìƒ‰ ìš”ì²­"""
    query: str = Field(..., min_length=1, max_length=1000)
    top_k: int = Field(default=5, ge=1, le=20)
    filters: Optional[dict] = Field(default=None)
    min_similarity: Optional[float] = Field(default=0.5, ge=0, le=1)

class SearchResultItem(BaseModel):
    """ê²€ìƒ‰ ê²°ê³¼ í•­ëª©"""
    content: str
    score: float
    source: str
    metadata: dict

class SearchResponse(BaseModel):
    """ê²€ìƒ‰ ì‘ë‹µ"""
    query: str
    results: List[SearchResultItem]
    total: int
    query_time_ms: float

class IndexRequest(BaseModel):
    """ì¸ë±ì‹± ìš”ì²­"""
    file_path: str
    collection: Optional[str] = "dubaicrab_docs"

class IndexResponse(BaseModel):
    """ì¸ë±ì‹± ì‘ë‹µ"""
    file_path: str
    chunks_indexed: int
    file_hash: str
    indexed_at: datetime

class CollectionInfo(BaseModel):
    """ì»¬ë ‰ì…˜ ì •ë³´"""
    name: str
    count: int
    created_at: Optional[datetime]
```

#### FastAPI ë¼ìš°í„°

```python
# src/rag/router.py

from fastapi import APIRouter, HTTPException, BackgroundTasks
from typing import List
import time

from .schemas import (
    SearchRequest, SearchResponse, SearchResultItem,
    IndexRequest, IndexResponse, CollectionInfo
)
from .pipeline import RAGPipeline
from .config import RAGSettings

router = APIRouter(prefix="/api/rag", tags=["RAG"])

# ì‹±ê¸€í†¤ íŒŒì´í”„ë¼ì¸
_pipeline: RAGPipeline = None

def get_pipeline() -> RAGPipeline:
    global _pipeline
    if _pipeline is None:
        _pipeline = RAGPipeline(RAGSettings())
    return _pipeline

@router.post("/search", response_model=SearchResponse)
async def search_documents(request: SearchRequest):
    """
    ë¬¸ì„œ ê²€ìƒ‰

    - **query**: ê²€ìƒ‰ ì¿¼ë¦¬ (í•œêµ­ì–´ ì§€ì›)
    - **top_k**: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ 5)
    - **filters**: ë©”íƒ€ë°ì´í„° í•„í„° (ì„ íƒ)
    """
    start_time = time.time()
    pipeline = get_pipeline()

    try:
        query_engine = pipeline.get_query_engine(
            similarity_top_k=request.top_k
        )
        response = query_engine.query(request.query)

        results = []
        for node in response.source_nodes:
            if node.score >= request.min_similarity:
                results.append(SearchResultItem(
                    content=node.text,
                    score=node.score,
                    source=node.metadata.get("source", "unknown"),
                    metadata=node.metadata
                ))

        return SearchResponse(
            query=request.query,
            results=results,
            total=len(results),
            query_time_ms=(time.time() - start_time) * 1000
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/index", response_model=IndexResponse)
async def index_document(
    request: IndexRequest,
    background_tasks: BackgroundTasks
):
    """
    ë¬¸ì„œ ì¸ë±ì‹±

    - **file_path**: ì¸ë±ì‹±í•  íŒŒì¼ ê²½ë¡œ
    - **collection**: ëŒ€ìƒ ì»¬ë ‰ì…˜ (ê¸°ë³¸: dubaicrab_docs)
    """
    pipeline = get_pipeline()

    # TODO: ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…ìœ¼ë¡œ ì²˜ë¦¬
    # background_tasks.add_task(pipeline.index_file, request.file_path)

    return IndexResponse(
        file_path=request.file_path,
        chunks_indexed=0,  # ì‹¤ì œ êµ¬í˜„ ì‹œ ì—…ë°ì´íŠ¸
        file_hash="",
        indexed_at=datetime.now()
    )

@router.get("/collections", response_model=List[CollectionInfo])
async def list_collections():
    """ëª¨ë“  ì»¬ë ‰ì…˜ ëª©ë¡"""
    pipeline = get_pipeline()
    collections = pipeline.vector_store.list_collections()

    return [
        CollectionInfo(name=name, count=0, created_at=None)
        for name in collections
    ]

@router.delete("/collection/{name}")
async def delete_collection(name: str):
    """ì»¬ë ‰ì…˜ ì‚­ì œ"""
    pipeline = get_pipeline()
    try:
        pipeline.vector_store.delete_collection(name)
        return {"message": f"ì»¬ë ‰ì…˜ '{name}' ì‚­ì œë¨"}
    except Exception as e:
        raise HTTPException(status_code=404, detail=str(e))

@router.get("/status")
async def get_status():
    """RAG ì‹œìŠ¤í…œ ìƒíƒœ"""
    pipeline = get_pipeline()
    return {
        "status": "healthy",
        "embedding_model": pipeline.config.embedding_model,
        "vector_store": "chroma",
        "collections": len(pipeline.vector_store.list_collections())
    }
```

---

## 4. ì˜ì¡´ì„± ë‹¤ì´ì–´ê·¸ë¨

```
P0-1: í™˜ê²½ ì„¤ì •
    â”‚
    â”œâ”€â”€â–¶ P0-2: HWP í…ìŠ¤íŠ¸ ì¶”ì¶œ
    â”‚         â”‚
    â”‚         â””â”€â”€â–¶ P0-3: ì²­í‚¹ íŒŒì´í”„ë¼ì¸
    â”‚                   â”‚
    â”‚                   â””â”€â”€â–¶ P0-4: ë²¡í„° ì¸ë±ì‹±
    â”‚                             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                                  â”‚
                                  â–¼
                         P1-1: ê²€ìƒ‰ ì—”ì§„
                                  â”‚
                                  â–¼
                         P1-2: FastAPI ì—”ë“œí¬ì¸íŠ¸
                                  â”‚
                                  â–¼
                         P1-3: ì±„íŒ… í†µí•©
                                  â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                        â–¼                        â–¼
P2-1: ë¦¬ë­í‚¹        P2-2: ë‹¤ì¤‘ íŒŒì¼ í˜•ì‹        P2-3: ê´€ë¦¬ UI
```

---

## 5. ë¦¬ìŠ¤í¬ ë° ì™„í™” ì „ëµ

| ë¦¬ìŠ¤í¬                    | ì˜í–¥ | í™•ë¥  | ì™„í™” ì „ëµ                      |
| ------------------------- | ---- | ---- | ------------------------------ |
| LibreOffice HWP ë³€í™˜ ì‹¤íŒ¨ | ë†’ìŒ | ì¤‘ê°„ | hwpx ìš°ì„  ì²˜ë¦¬, ëŒ€ì²´ íŒŒì„œ ì¤€ë¹„ |
| BGE-M3 ë©”ëª¨ë¦¬ ë¶€ì¡±        | ì¤‘ê°„ | ë‚®ìŒ | FP16 ëª¨ë“œ, ë°°ì¹˜ í¬ê¸° ì¡°ì ˆ      |
| Chroma ì„±ëŠ¥ ë³‘ëª©          | ì¤‘ê°„ | ë‚®ìŒ | Qdrant ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš       |
| í•œêµ­ì–´ ì²­í‚¹ í’ˆì§ˆ          | ì¤‘ê°„ | ì¤‘ê°„ | KoNLPy í˜•íƒœì†Œ ë¶„ì„ í†µí•©        |

---

## 6. ì„±ê³µ ê¸°ì¤€ (Definition of Done)

### Sprint ì™„ë£Œ ê¸°ì¤€

1. **P0 100% ì™„ë£Œ**
   - [ ] Chroma + BGE-M3 í™˜ê²½ êµ¬ì¶•
   - [ ] HWP 10ê°œ íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ
   - [ ] 100ê°œ ë¬¸ì„œ ì¸ë±ì‹± < 5ë¶„

2. **P1 100% ì™„ë£Œ**
   - [ ] ê²€ìƒ‰ API ì •ìƒ ë™ì‘
   - [ ] Swagger UI í…ŒìŠ¤íŠ¸ í†µê³¼
   - [ ] ì±„íŒ…ì—ì„œ RAG ì»¨í…ìŠ¤íŠ¸ í™œìš©

3. **í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€**
   - [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ 70%+
   - [ ] í†µí•© í…ŒìŠ¤íŠ¸ 3ê°œ+

4. **ë¬¸ì„œí™”**
   - [ ] API ë¬¸ì„œ (Swagger)
   - [ ] ì‚¬ìš©ì ê°€ì´ë“œ

---

## 7. ì°¸ê³  ìë£Œ

- [ë¦¬ì„œì¹˜ ë¬¸ì„œ](./2026-02-09-research-rag.md)
- [LlamaIndex ë¬¸ì„œ](https://docs.llamaindex.ai/)
- [Chroma ë¬¸ì„œ](https://docs.trychroma.com/)
- [BGE-M3 GitHub](https://github.com/FlagOpen/FlagEmbedding)

---

_ì‘ì„±ì: Ralph (PM Agent)_  
_ê²€í†  í•„ìš”: ê¸°ìˆ  ìŠ¤í™ ê²€ì¦_
